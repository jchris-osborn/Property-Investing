import numpy as np
import pandas as pd
import requests
import bs4
import lxml.etree as xml
from selenium import webdriver
import os
import time
import csv
from google.colab import files

#IMPORTING DATA
file = pd.read_csv("/content/zip_codes.csv")

#CREATING DATAFRAME
data = pd.DataFrame(file)
print(data.head())

#removing useless columns
col = ["StateName", "State", "City", "Metro", "CountyName", "SizeRank", 
       "RegionType", "RegionID"]
data = data.drop(columns = col )
print(data.head())

zips = data['RegionName'].tolist()

zips = zips[24001:27000]

options = webdriver.ChromeOptions()
options.add_argument('--headless')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')

driver = webdriver.Chrome('chromedriver',options=options)

walk_scores = {}
err_list = [] 

for query in zipcodes:
  try:
    thing_url = "https://www.walkscore.com/"
    driver.get(thing_url)
    time.sleep(1)

    searchbox = driver.find_element_by_id("gs-street")
    searchbox.click()
    searchbox.send_keys(str(query))

    submit_button = driver.find_element_by_xpath('/html/body/div[3]/div[2]/div/div[1]/div/form/button/span')
    submit_button.click()

    window_after = driver.window_handles[0]
    driver.switch_to.window(window_after)
    time.sleep(1)

    page = driver.current_url
    r = requests.get(page)
    soup = bs4.BeautifulSoup(r.content, "html.parser")

    for item in soup.find_all('img'):
      if 'walk/score' in str(item['src']):
        split_string = item['src'].split('/')
        score = split_string[-1]
        score_split = score.split('.')
        walk_scores[query] = score_split[0]
        break
   
  except Exception as e:
    print(e)
    err_list.append(query)

for query in zipcodes:
  if query not in walk_scores.keys():
    walk_scores[query] = 0  

df = pd.DataFrame.from_dict(data=walk_scores, orient='index')

er = pd.DataFrame(err_list)

df.to_csv('walkscore14.csv')
er.to_csv('error14.csv')

files.download("walkscore14.csv")
files.download('error14.csv')
